---
title: "Review of LQAS Sampling Plan Calculator"
author: "Team 2"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Source link: [Brixton Health's sampling plan calculator](http://www.brixtonhealth.com/hyperLQAS.findD.html)

## 1. The sampling design

1. Sampling assumptions: simple random sampling without replacement.

2. Type of accuracy used for the calculator:
* no mention of confidence interval
* no mention of coefficient of variation
* other: type I error, $\alpha$, and type II error, $\beta$.

3. The calculator only performs sampling plan calculation for single sampling.

4. LQAS is identical to stratified sampling in which the samples are too small to provide acceptably narrow confidence intervals for estimates (Lemeshow and Stroh, 1989).

5. Deal with proportion.

6. No mention of non-response.

7. Clustering not applicable. 

8. No mention of design effect.

9. Study type(s) this calculator would be suitable for: 
* Point in time surveys to estimate a proportion
* Humanitarian surveys
* Comparative surveys


## 2. Checking the calculator calculation

**Summary:** the calculation of actual $\alpha$ and actual $\beta$ that *brixtonhealth* calculator generates are correct and identical to the approach described in Lemeshow and Stroh (1989). Its resulting decision rule is slightly different than the decision rule that we calculated using Lemeshow and Stroh (1989) as reference. The *brixtonhealth* calculator uses hypergeometric distribution rather than normal approximation of hypergeometric distribution.

The *brixtonhealth* calculator uses the following default specifications:

* Population size, $N = 600$

* Upper threshold, $P_0 = 0.8$

* Lower threshold, $P_a = 0.5$

* Sample size, $n = 50$

* Maximum tolerable $\alpha$ error = 0.1

* Maximum tolerable $\beta$ error = 0.1


```{r}
# specifications
N <- 600      # population size
n <- 50       # sample size
p_0 <- 0.8    # upper threshold
p_a <- 0.5    # lower threshold
alpha <- 0.1
beta <- 0.1

```


### 2.1 Check brixtonhealth calculation using Lemeshow and Stroh (1989) as reference


**Check actual alpha and actual beta: ** 

Using the above specifications, the *brixtonhealth* calculator generates decision rule $d^*$ = 33, actual $\alpha$ error = 0.0110, and actual $\beta$ error = 0.0057.

With $d^*$ = 33, we check the calculation of $\alpha$ and $\beta$:  

```{r}
type1_error_hyper <- phyper(q=33, m = N*p_0, n = (N-N*p_0), k = n)
type1_error_hyper
```

```{r}
power_of_test <- phyper(q=33, m = N*p_a, n = (N-N*p_a), k = n)
type2_error_hyper <- 1 - power_of_test
type2_error_hyper
```

We expect to get identical results as *brixtonhealth* calculator generates. That is, type 1 error = 0.0110 and type 2 error = 0.0057. We get `r round(type1_error_hyper,4)` and `r round(type2_error_hyper,4)` for type 1 error and type 2 error, respectively. Our calculation of actual $\alpha$ and actual $\beta$ are identical to those of *brixtonhealth* calculator. 

**Check decision rule:**

```{r}
# create a function to find d*, decision rule based on alpha
find_dstar <- function(N, p, n, alpha){
  dstar = 0
  for (i in seq(n)) {
    type_1_error <- phyper(q=i, m = N*p, n = (N-N*p), k = n)
    if (type_1_error <= alpha) {
      dstar = i
    }
  }
  return(dstar)
}
```

```{r}
d_star <- find_dstar(N=N, p=p_0, n=n, alpha=alpha)
d_star
```

```{r}
# recheck the resulting type 1 error
type1_error_hyper <- phyper(q=d_star, m = N*p_0, n = (N-N*p_0), k = n)
type1_error_hyper
```

Resulting actual $\alpha$ is `r round(type1_error_hyper,4)`, lower than the maximum allowable $\alpha$ of 0.1.

```{r}
# check type 2 error using d_star
power_of_test <- phyper(q=d_star, m = N*p_a, n = (N-N*p_a), k = n)
type2_error_hyper <- 1 - power_of_test
type2_error_hyper
```

Resulting actual $\beta$ is `r round(type2_error_hyper,4)`, lower than the maximum tolerable $\beta$ of 0.1.

We expect to get decision rule of 33, as generated by *brixtonhealth* calculator. But, our calculation thus far yields decision rule of 35. 

Next, we explore the possibility of considering maximum tolerable $\beta$ in generating decision rule.

```{r}
# find d* based on beta
d_star_beta <- find_dstar(N=N, p=p_a, n=n, alpha=beta)
d_star_beta

```

```{r}
# check type 1 error based on d_star_beta
phyper(q=d_star_beta, m = N*p_0, n = (N-N*p_0), k = n)

```

```{r}
# check type 2 error based on d_star_beta
power_tmp <- phyper(q=d_star_beta, m = N*p_a, n = (N-N*p_a), k = n)
type_2_error <- 1-power_tmp
type_2_error
```

Considering $\beta$ does not lead to decision rule of 33, as generated by *brexithealth* calculator.

Next we consider decision rule based on $\alpha$ as a starting point, and progressively reduces it until it reach the maximum tolerable $\beta$

```{r}
type1_error_hyper
```

```{r}
type2_error_hyper
```

```{r}
# type 1 error using alternative decision rule
phyper(q=d_star-6, m = N*p_0, n = (N-N*p_0), k = n)
```
```{r}
# type 2 error using alternative decision rule
1 - phyper(q=d_star-6, m = N*p_a, n = (N-N*p_a), k = n)
```

```{r}
d_star-6
```

This approach results in decision rule of 29.


### 2.2 Check brixtonhealth calculation using Lemeshow & Taber (1991) as reference

Lemeshow & Taber (1991) uses normal approximation to hypergeometric distribution. 

Hypergeometric distribution is represented by the following formula:
$$
\mathrm{P}(d \le d^*) = \sum_{d=0}^{d^*} \frac{\binom{NP_0}{d} \binom{N(1-P_0)}{n-d}}{\binom{N}{n}}
$$
The mean and variance of hypergeometric distribution with sample size $n$ and the hypothesized proportion $P_0$ are:

$$
\mathrm{mean}(d) = nP_0
$$
and
$$
\mathrm{var}(d) = nP_0(1-P_0)\left( \frac{N-n}{N-1} \right)
$$

If the calculator uses normal approximation to the hypergeometric distribution, then $d$ would be calculated as:
$$
d^* = nP_0 - z_{1-\alpha} \sqrt{nP_0(1-P_0)\left( \frac{N-n}{N-1}\right)}  
$$
Because $P_a$ and $\beta$ are also specified in the calculator, 

$$
d^* = nP_0 - z_{1-\beta} \sqrt{nP_a(1-P_a)\left( \frac{N-n}{N-1}\right)}  
$$

Setting the above two equations for $d$ equal to each other, and solving for $n$:
$$
n = \left(\frac{z_{1-\alpha} \sqrt{P_0(1-P_0)} + z_{1-\beta} \sqrt{P_a(1-P_a)}}{(P_0 - P_a)}  \right)^2
$$


```{r}
N <- 1000000 # set population size so that N >> n

z_0 <- qnorm(alpha, lower.tail = FALSE)
paste0("z_0: ", round(z_0,3))
z_a <- qnorm(beta, lower.tail = FALSE)
paste0("z_a: ", round(z_a,3))

# calculate n that makes the two d* equations equals
numer <- z_0*sqrt(p_0*(1-p_0)) + z_a*sqrt(p_a*(1-p_a))
denom <- p_0 - p_a

n_calc <- ceiling((numer / denom)^2)
d_star <- n_calc*p_0 - (z_0 * sqrt(n_calc*p_0*(1-p_0)))

paste0("n: ", n_calc)
paste0("d_star: ", ceiling(d_star))
```

We expect to get identical results as *brexithealth* calculator generates. That is, decision rule = 33. However, we get decision rule =  `r ceiling(d_star)`.

It could be that we do not get decision rule of 33 because we use maximum tolerable $\alpha$ and $\beta$ instead of actual $\alpha$ and actual $\beta$. We recalculate decision rule using actual $\alpha$ = 0.0110 and actual $\beta$ = 0.0057.

```{r}
actual_alpha <- 0.0110
actual_beta <- 0.0057

z_0_act <- qnorm(actual_alpha, lower.tail = FALSE)
paste0("z_0: ", round(z_0_act,3))
z_a_act <- qnorm(actual_beta, lower.tail = FALSE)
paste0("z_a: ", round(z_a_act,3))

# calculate n that makes the two d* equations equals
numer <- z_0*sqrt(p_0*(1-p_0)) + z_a*sqrt(p_a*(1-p_a))
denom <- p_0 - p_a

n_calc <- ceiling((numer / denom)^2)
d_star <- n_calc*p_0 - (z_0 * sqrt(n_calc*p_0*(1-p_0)))

paste0("n: ", n_calc)
paste0("d_star: ", ceiling(d_star))

```

The decision rule using actual $\alpha$ and actual $\beta$ is `r ceiling(d_star)`. It remains different from decision rule generated by *brexithealth*.

Conclusion: the *brexithealth* calculator does not seem to use normal approximation to hypergeometric distribution.


